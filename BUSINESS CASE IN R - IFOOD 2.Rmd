---
title: "Business Case - iFood"
author: "Maycon Macedo"
---

```{r, include=FALSE, mychunk}
# Instalar bibliotecas se não tiver instalado no ambiente

#install.packages('skimr')
#install.packages('dplyr')
#install.packages('corrplot')
#install.packages("RColorBrewer")
#install.packages('ggpubr')
#install.packages('psych')
#install.packages('caret')
#install.packages('rpart')
#install.packages('e1071')

```

```{r, include=FALSE, mychunk}

# Carregando bibliotecas

library(skimr)
library(dplyr)
library(corrplot)
library(ggplot2)
library(RColorBrewer)
library(ggpubr)
library(psych)
library(caret)
library(rpart)
library(e1071)
library(gbm)

```

```{r echo=FALSE}

# Importando o arquivo csv
dados <- read.csv('ml_project1_data.csv')

# ANÁLISE EXPLORATÓRIA

# análise geral

dados %>% skim()

```

```{r echo=FALSE}

# Removendo colunas que não estão nos metadados do PDF do case

dados <- dplyr::select(dados, -c("ID","Z_Revenue" ,"Z_CostContact","Year_Birth"))

# Missing Values

# Há 24 dados faltantes. Todos na coluna Income. Diante do tamanho do dateset, 
# eu apenas irei excluir os registros que tiverem pelo menos um dado faltante,
# pois não irá impactar nos resultados finais da previsão.

dados <- dados[!is.na(dados$Income),]

#Transformando colunas booleanas
dados$AcceptedCmp1 <- as.logical(dados$AcceptedCmp1)
dados$AcceptedCmp2 <- as.logical(dados$AcceptedCmp2)
dados$AcceptedCmp3 <- as.logical(dados$AcceptedCmp3)
dados$AcceptedCmp4 <- as.logical(dados$AcceptedCmp4)
dados$AcceptedCmp5 <- as.logical(dados$AcceptedCmp5)
dados$Response <- as.logical(dados$Response)
dados$Complain <- as.logical(dados$Complain)

```

```{r echo=FALSE}

# Verificando a variável dependente

summary(as.factor(dados$Response))

# Conforme resultado abaixo, podemos verificar que há poucos registros em que os clientes aceitaram a oferta na última campanha em comparação com aqueles que não aceitaram. Devemos treinar um modelo que consiga acertar o máximo possível destes casos positivos, uma vez que há uma proporção muito desigual e que o próprio algoritmo irá ter dificuldades para aprender de forma consistente por conta disso.

```

```{r echo=FALSE}

# Correlação entre as variáveis numéricas

numericVars <- which(sapply(dados, is.numeric))
numericVars <- names(numericVars)

correlacao <- cor(dados[,numericVars], use = 'pairwise.complete.obs')

corrplot(correlacao, tl.col="black", tl.pos = "lt", )

```

```{r echo=FALSE}

# As variáveis MntMeatProducts e NumCatalogPurchases têm alta correlação positiva de 73%. Isto quer dizer que num contexto lógico, quanto maior as compras por catálogo, maior será o valor gasto com carne.

best_cor <- sort(correlacao[,'MntMeatProducts'], decreasing = TRUE)
best_cor[2]*100

```

```{r echo=FALSE}

# Plotando as variáveis percebe-se que existem alguns valores altos que irei considerar como outliers.

reg <- lm(NumCatalogPurchases~MntMeatProducts, data = dados)

plot(NumCatalogPurchases~MntMeatProducts, data = dados, main = 'Plotagem das variáveis e linha ajustada da regressão')
abline(reg, col = 'red', lwd = 4)

```
```{r echo=FALSE}

# Sumário da regressão linear com os outliers
summary(reg)

```

```{r echo=FALSE}

# Irei retirar os outliers do dataset e verificar novamente a correlação e os resultados através de uma regressão linear entre essas duas variáveis.

subset <- filter(dados, dados$MntMeatProducts < 1500 & dados$NumCatalogPurchases < 15)

reg <- lm(NumCatalogPurchases~MntMeatProducts, data = subset)

plot(NumCatalogPurchases~MntMeatProducts, data = subset, main = 'Plotagem das variáveis e linha ajustada da regressão')
abline(reg, col = 'red', lwd = 4)

```

```{r echo=FALSE}

# Sumário da regressão linear sem os outliers
summary(reg)

```

```{r echo=FALSE}

# Nova correlação sem outliers

correlacao <- cor(subset[,numericVars], use = 'pairwise.complete.obs')

best_cor <- sort(correlacao[,'MntMeatProducts'], decreasing = TRUE)
best_cor[2]*100


```

```{r echo=FALSE}

# Irei desconsiderar a variável MntMeatProducts por conta dela ter uma alta correlação com a variável NumCatalogPurchases. P-value do t-value do MntMeatProducts na regressão linear é <2e-16. Tendo alta correlação entre o intercepto do modelo e a variável independente.

subset <- select(subset,-c('MntMeatProducts'))

# Análise geral

subset %>% skim()

```

```{r echo=FALSE}

# Analisando distriuição dos dados no gráfico, percebe-se cauda alongada à direita. Terá que ser feito feature engineering utilizando log dos valores dos dados para reduzir esta cauda.

s1 <- ggplot(data= subset, aes(x=MntWines)) +
        geom_density() + labs(x='MntWines')
s2 <- ggplot(data=subset, aes(x=MntFruits)) +
        geom_density() + labs(x='MntFruits')
s4 <- ggplot(data= subset, aes(x=MntFishProducts)) +
        geom_density() + labs(x='MntFishProducts')
s5 <- ggplot(data= subset, aes(x=MntSweetProducts)) +
        geom_density() + labs(x='MntSweetProducts')
s6 <- ggplot(data= subset, aes(x=MntGoldProds)) +
        geom_density() + labs(x='MntGoldProds')
s7 <- ggplot(data= subset, aes(x=Income)) +
        geom_density() + labs(x='Income')
s8 <- ggplot(data= subset, aes(x=NumDealsPurchases)) +
        geom_density() + labs(x='NumDealsPurchases')
s9 <- ggplot(data= subset, aes(x=NumWebPurchases)) +
        geom_density() + labs(x='NumWebPurchases')
s10 <- ggplot(data= subset, aes(x=NumCatalogPurchases)) +
        geom_density() + labs(x='NumCatalogPurchases')
s11 <- ggplot(data= subset, aes(x=NumStorePurchases)) +
        geom_density() + labs(x='NumStorePurchases')
s12 <- ggplot(data= subset, aes(x=NumWebVisitsMonth)) +
        geom_density() + labs(x='NumWebVisitsMonth')

ggarrange(s1,s2,s4,s5,s6, ncol = 3, nrow = 2)

ggarrange(s7,s8,s9,s10,s11,s12, ncol = 3, nrow = 2)

```

```{r echo=FALSE}

# Visualizando boxplot de variáveis numéricos pela categoria Education

s1 <- ggplot(data= subset, aes(y=MntWines, x= Education)) +
        geom_boxplot(aes(fill = Education)) + labs(y='MntWines', x= 'Education') +
        scale_fill_brewer(palette = "Dark2")

s2 <- ggplot(data=subset, aes(y=MntFruits, x= Education)) +
        geom_boxplot(aes(fill = Education)) + labs(y='MntFruits', x= 'Education') + 
        scale_fill_brewer(palette = "Dark2")

s4 <- ggplot(data= subset, aes(y=MntFishProducts, x= Education)) +
        geom_boxplot(aes(fill = Education)) + labs(y='MntFishProducts', x= 'Education') + 
        scale_fill_brewer(palette = "Dark2")

s5 <- ggplot(data= subset, aes(y=MntSweetProducts, x= Education)) +
        geom_boxplot(aes(fill = Education)) + labs(y='MntSweetProducts', x= 'Education') + 
        scale_fill_brewer(palette = "Dark2")

s6 <- ggplot(data= subset, aes(y=MntGoldProds, x= Education)) +
        geom_boxplot(aes(fill = Education)) + labs(y='MntGoldProds', x= 'Education') + 
        scale_fill_brewer(palette = "Dark2")

s7 <- ggplot(data= subset, aes(y=Income, x= Education)) +
        geom_boxplot(aes(fill = Education)) + labs(y='Income', x= 'Education') + 
        scale_fill_brewer(palette = "Dark2")

s8 <- ggplot(data= subset, aes(y=NumDealsPurchases, x= Education)) +
        geom_boxplot(aes(fill = Education)) + labs(y='NumDealsPurchases', x= 'Education') + 
        scale_fill_brewer(palette = "Dark2")

s9 <- ggplot(data= subset, aes(y=NumWebPurchases, x= Education)) +
        geom_boxplot(aes(fill = Education)) + labs(y='NumWebPurchases', x= 'Education') + 
        scale_fill_brewer(palette = "Dark2")

s10 <- ggplot(data= subset, aes(y=NumCatalogPurchases, x= Education)) +
        geom_boxplot(aes(fill = Education)) + labs(y='NumCatalogPurchases', x= 'Education') + 
        scale_fill_brewer(palette = "Dark2")

s11 <- ggplot(data= subset, aes(y=NumStorePurchases, x= Education)) +
        geom_boxplot(aes(fill = Education)) + labs(y='NumStorePurchases', x= 'Education') + 
        scale_fill_brewer(palette = "Dark2")

s12 <- ggplot(data= subset, aes(y=NumWebVisitsMonth, x= Education)) +
        geom_boxplot(aes(fill = Education)) + labs(y='NumWebVisitsMonth', x= 'Education') + 
        scale_fill_brewer(palette = "Dark2")

ggarrange(s1,s2, ncol = 1, nrow = 2)
ggarrange(s4, ncol = 1, nrow = 1)
ggarrange(s5,s6, ncol = 1, nrow = 2)
ggarrange(s7,s8, ncol = 1, nrow = 2)
ggarrange(s9,s10, ncol = 1, nrow = 2)
ggarrange(s11,s12, ncol = 1, nrow = 2)

```

```{r echo=FALSE}

# Analisando a gráfico boxplot de Income

ggplot(data= subset, aes(y=Income)) + 
      geom_boxplot(fill = '#C70039', color = '#FF5733') + labs(y='Income') +
      scale_y_continuous(breaks= seq(0, 700000, by=25000))

```

```{r echo=FALSE}

# Analisando mais a fundo a variável Income

ggqqplot(subset$Income)

shapiro.test(subset$Income)

print('Skew')
skew(subset$Income)

# Conforme analisado abaixo, o teste de Shapiro-Wilk indica se a variável está normalmente distribuída ou não. A hipótese nula do teste de Shapiro-Wilk é que a população possui distribuição normal. Portanto, um valor de p < 0.05 indica que se rejeitou a hipótese nula, ou seja, os dados não possuem distribuição normal que aliás é o caso da variável Income.

# O Skewness mede a simetria dos dados. Se os dados estiverem normalmente distribuídos, o resultado tende a estar perto de zero.Se estiver assimétrico à esquerda, o resultado skew será negativo. Se estiver assimétrico à direita, o resultado será positivo. O resultado da variável Income está em torno de 6.93 conforme resultado abaixo.

```

```{r echo=FALSE}

# Irei retirar o Income de maior valor, pois de acordo com o gráfico acima, é um outlier bem enviesado no nosso dataset

subset1 <- filter(subset, subset$Income < 250000 )

ggplot(data= subset1, aes(y=Income)) + 
      geom_boxplot(fill = '#C70039', color = '#FF5733') + labs(y='Income') +
      scale_y_continuous(breaks= seq(0, 700000, by=25000))

```

```{r echo=FALSE}

# Verificando a variável Income depois de retirar o outlier.

ggqqplot(subset1$Income)

shapiro.test(subset1$Income)

print('Skew')
skew(subset1$Income)

```

```{r echo=FALSE}

# Analisando as variáveis qualitativas

# Marital Status
summary(as.factor(subset1$Marital_Status))

# Irei excluir registros que contenham Absurd ou YOLO, pois eu não faço ideia o que seja e por conterem menos de 5 registros no total.
subset2 <- subset1[!(subset1$Marital_Status %in% c('Absurd','YOLO')),]

# Irei atribuir Alone como Single
subset2$Marital_Status <- ifelse(subset2$Marital_Status == 'Alone', "Single", subset2$Marital_Status)

summary(as.factor(subset2$Marital_Status))

```

```{r echo=FALSE}

# FEATURE ENGINEERING

# Normalizando variáveis numéricas com skew maior que 0.6 ou menor que -0.6 com log e pré-processamento.

numericVars <- which(sapply(subset2, is.numeric))
numericVars <- names(numericVars)

skewed <- as.data.frame(ifelse(skew(subset2[,numericVars]) > 0.8 | skew(subset2[,numericVars]) < -0.8, log(subset2[,numericVars]+1),subset2[,numericVars]))


colnames(skewed) <- numericVars

# Pré-procesando dataset

# preNumVars <- preProcess(skewed, method = c('center','scale'),na.remove = T)
# preNumVars
# trainClean_NumVars <- predict(preNumVars,skewed)


```

```{r echo=FALSE}

# One-hot encoding na única variável não ordinal - Marital_Status

dummy <- dummyVars(" ~ Marital_Status ", data = subset2, fullRank = T)

dt_dummied <- data.frame(predict(dummy, newdata = subset2))

```

```{r echo=FALSE}

# Ordinal encoding na variável Education

skewed$Education.ord <- ifelse(subset2$Education == 'Basic', 1,
                                ifelse(subset2$Education == '2n Cycle',2,
                                       ifelse(subset2$Education == 'Graduation', 3,
                                              ifelse(subset2$Education == 'Master', 4, 5))))

```

```{r echo=FALSE}

# Irei excluir a variável Dt_Customer pois julguei não ser importante para este caso
subset2$Dt_Customer <- NULL


# Combinando o dataset final para fazermos nossa previsão.
dataset4 <- cbind(dt_dummied, skewed, subset2[,17:23])

# Revertendo as colunas booleanas
dataset4$AcceptedCmp1 <- as.numeric(dataset4$AcceptedCmp1)
dataset4$AcceptedCmp2 <- as.numeric(dataset4$AcceptedCmp2)
dataset4$AcceptedCmp3 <- as.numeric(dataset4$AcceptedCmp3)
dataset4$AcceptedCmp4 <- as.numeric(dataset4$AcceptedCmp4)
dataset4$AcceptedCmp5 <- as.numeric(dataset4$AcceptedCmp5)
dataset4$Response <- as.numeric(dataset4$Response)
dataset4$Complain <- as.numeric(dataset4$Complain)

```

```{r echo=FALSE}

# Revertendo as colunas em fatores
dataset4$Marital_StatusMarried <- as.factor(dataset4$Marital_StatusMarried)
dataset4$Marital_StatusSingle <- as.factor(dataset4$Marital_StatusSingle)
dataset4$Marital_StatusTogether <- as.factor(dataset4$Marital_StatusTogether)
dataset4$Marital_StatusWidow <- as.factor(dataset4$Marital_StatusWidow)
dataset4$AcceptedCmp1 <- as.factor(dataset4$AcceptedCmp1)
dataset4$AcceptedCmp2 <- as.factor(dataset4$AcceptedCmp2)
dataset4$AcceptedCmp3 <- as.factor(dataset4$AcceptedCmp3)
dataset4$AcceptedCmp4 <- as.factor(dataset4$AcceptedCmp4)
dataset4$AcceptedCmp5 <- as.factor(dataset4$AcceptedCmp5)
dataset4$Response <- as.factor(dataset4$Response)
dataset4$Complain <- as.factor(dataset4$Complain)


# Amostra Houldout

amostra = sample(2,dim(dataset4)[1], replace = T, prob = c(0.75,0.25))

treino = dataset4[amostra==1,] 

teste = dataset4[amostra==2,]

```

```{r echo=FALSE}

# Depois de rodar vários modelos de todos os tipos, eu escolhi GLM com Stepwise AIC, pois ele teve a maior Sensibilidade, diante da análise da matriz de confusão. Isto é, o modelo conseguiu prever uma maior proporção de casos positivos comparado com os outros modelos que eu testei. Além de ter tido uma acurácia bem relevante também.

# Neste caso, utilizei pré-processamento para centralizar e escalar a distribuição, mas neste modelo não obtive diferença se eu não tivesse utilizado, diferente dos outros modelos.

# Utilizei cross-validation para que o modelo não causasse overfitting.

# A variável complain foi inútil na maioria dos modelos treinados, porém como o Stepwise utiliza somente as melhores variáveis de acordo com o AIC, decidi mantê-lo no dataset.

glm_model = train(Response ~ . , data = treino, method = 'glmStepAIC', trControl = trainControl(method = "cv", number = 20), verbose = F, preProcess = c('center', 'scale'))

plot(varImp(glm_model))

# Testando modelo
resultado = predict(glm_model, newdata = teste[,1:26])

# Matriz de Confusão
confusionMatrix(data = resultado, reference = teste$Response, positive = "1")

```

```{r echo=FALSE}

# Segmentation

# Revertendo as colunas booleanas
subset2$AcceptedCmp1 <- as.numeric(subset2$AcceptedCmp1)
subset2$AcceptedCmp2 <- as.numeric(subset2$AcceptedCmp2)
subset2$AcceptedCmp3 <- as.numeric(subset2$AcceptedCmp3)
subset2$AcceptedCmp4 <- as.numeric(subset2$AcceptedCmp4)
subset2$AcceptedCmp5 <- as.numeric(subset2$AcceptedCmp5)
subset2$Response <- as.numeric(subset2$Response)
subset2$Complain <- as.numeric(subset2$Complain)

# Irei utilizar K-Means para analisar a segmentação de consumidores

cluster = kmeans(subset2[,c(3,7:17)], center = 3)

# Gráfico

s1 <- plot(subset2[,7], subset2[,3], col=cluster$cluster, xlab = 'Gastos com vinhos nos últimos 2 anos', ylab = 'Renda anual familiar do consumidor')

s2 <- plot(subset2[,8], subset2[,3], col=cluster$cluster, xlab = 'Gastos com frutas nos últimos 2 anos', ylab = 'Renda anual familiar do consumidor')

s4 <- plot(subset2[,9], subset2[,3], col=cluster$cluster, xlab = 'Gastos com peixe nos últimos 2 anos', ylab = 'Renda anual familiar do consumidor')

s5 <- plot(subset2[,10], subset2[,3], col=cluster$cluster, xlab = 'Gastos com doces nos últimos 2 anos', ylab = 'Renda anual familiar do consumidor')

s6 <- plot(subset2[,11], subset2[,3], col=cluster$cluster, xlab = 'Gastos com produtos premium nos últimos 2 anos', ylab = 'Renda anual familiar do consumidor')

# Achei um insight referente a segmentação dos consumidores.

# - Os consumidores com as maiores renda anual familiar são os que mais gastaram com produtos nos últimos 2 anos conforme os gráficos.

# Na verdade isto se aplica a qualquer montante gasto, seja vinho, peixe, doce, pois a renda familiar do consumidor está diretamente proporcional ao poder de consumo destes bens.

```

```{r echo=FALSE}

# Agora um fato interessante é que os consumidores com as menores rendas familiares são os que mais acessaram o site da empresa no último mês

plot(subset2[,16], subset2[,3], col=cluster$cluster, xlab = 'Número de visitas ao site da empresa no último mês', ylab = 'Renda anual familiar do consumidor')

```
